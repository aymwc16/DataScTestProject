{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook aims to automate data extraction from a zip file. We assume that we manually downloaded the dataset in a `.zip` file. We will store the relevant datasets under the `CSV` data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from alive_progress import alive_bar\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzipping the `.zip` files\n",
    "This cell unzips all `.zip` files at once present in `data_extraction` when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPS = glob.glob(\"./*.zip\")\n",
    "UNZIP_TARGETS = [re.findall(\"/(.*).zip\",zip_file)[0] for zip_file in ZIPS]\n",
    "extracted_names = [glob.glob(\"./{}/\".format(target)) for target in UNZIP_TARGETS]\n",
    "to_extract = [ZIPS[f] for f in range(len(UNZIP_TARGETS)) if UNZIP_TARGETS[f] not in extracted_names]\n",
    "\n",
    "print(to_extract)\n",
    "\n",
    "if len(to_extract)==0:\n",
    "    print(\"zip files were already extracted\")\n",
    "    pass\n",
    "elif len(ZIPS)>len(to_extract):\n",
    "    raise ValueError(\"Error:\\tYou cannot have more zip files than unzip ones. Clean /data_extraction and /data\")\n",
    "else:\n",
    "    with alive_bar(total=len(to_extract), title='Unizipping', force_tty=True) as pbar:\n",
    "        for target in to_extract:\n",
    "            with ZipFile(target,'r') as handle:\n",
    "                handle.extractall()\n",
    "            pbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving `.npz` files into a `data` directory\n",
    "Checks if the `data` directory exists, creates it if necessary. It will overwrite previous files and repopulate the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    target_dir = os.listdir('./../data/')\n",
    "except:\n",
    "    os.mkdir('./../data/')\n",
    "    target_dir = []\n",
    "\n",
    "for target in UNZIP_TARGETS:\n",
    "    Files = glob.glob(\"./{}/*.npz\".format(target))\n",
    "    #File_names = [re.findall(\"/(.*)$\") for file in Files]\n",
    "    Data_files = glob.glob(\"./../data/*.npz\".format(target))\n",
    "    \n",
    "    if len(Files)==0:\n",
    "        print('npz files were already moved for {}'.format(target))\n",
    "    else:\n",
    "        with alive_bar(total=len(Files), title='Moving npz files from {}/ to /data'.format(target), force_tty=True) as pbar:\n",
    "            for file in Files:\n",
    "                file_name = re.findall(\"([^/]+)$\",file)[-1]\n",
    "                if file_name not in Data_files: \n",
    "                    shutil.copy(file, \"./../data/{}_{}\".format(target,file_name))\n",
    "                else:\n",
    "                    os.remove(file)\n",
    "                    shutil.copy(file, \"./../data/{}_{}\".format(target,file_name))\n",
    "                pbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion to `CSV` files\n",
    "We only convert `.npz` with the `np.load` command.\n",
    "After checking that each `.npz` files contains the same columns from the previous to next `.npz`, we then extract those values and create a corresponding `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking the entries of each .npz file\n",
    "checker_memory = []\n",
    "\n",
    "for file in glob.glob('./../data/*.npz'):\n",
    "    checker = np.load(file).files\n",
    "    if not np.array_equal(checker,checker_memory) and not np.array_equal(checker_memory,[]):\n",
    "        raise ValueError(\"Error: Data inconsistency!\")\n",
    "    else:\n",
    "        checker_memory = np.copy(checker)\n",
    "print(\"Data is consistent with entries:\\n{}\".format(checker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Careful, this next cell takes time to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "### Accelerating csv generation with parallelization\n",
    "npz_files_name = glob.glob('./../data/*.npz')\n",
    "already_processed_npz = glob.glob('./../data/*.csv')\n",
    "overwrite = False\n",
    "\n",
    "def pooled_csv_generation(npz_task):\n",
    "    npz_file = npz_task\n",
    "    file_name = re.findall(\"data\\/(.*)npz$\",npz_file)[0]\n",
    "    file_path = './../data/' + file_name + 'csv' \n",
    "    print(\"[{}]\\tGenerating {}csv\".format(datetime.utcnow(),\n",
    "                                            file_name))\n",
    "    df = pd.DataFrame() # 'df' stands for 'dataframe'\n",
    "    data = np.load(npz_file)\n",
    "    data_files = data.files\n",
    "    for data_entry in data_files:\n",
    "        print(\"[{}]\\t{}csv:\\tprocessing '{}'\".format(datetime.utcnow(),\n",
    "                                                       file_name,\n",
    "                                                       data_entry))\n",
    "        array_shaped_data = data[data_entry]\n",
    "        try:\n",
    "            number_of_columns = array_shaped_data.shape[1]\n",
    "            for i in range(number_of_columns):\n",
    "                column_name = data_entry+str(i+1)\n",
    "                df[column_name] = array_shaped_data[:,i]\n",
    "        except:\n",
    "            column_name = data_entry\n",
    "            df[column_name] = array_shaped_data\n",
    "    df.to_csv(path_or_buf=file_path)\n",
    "    print(\"[{}]\\tFinished generating {}csv!\".format(datetime.utcnow(),\n",
    "                                                    file_name))\n",
    "\n",
    "\n",
    "### Launching processes\n",
    "if __name__ == '__main__':\n",
    "    if overwrite:\n",
    "        for file in already_processed_npz:\n",
    "            try:\n",
    "                os.remove(file)\n",
    "            except:\n",
    "                pass\n",
    "    pool = Pool(processes=4)\n",
    "    pool.map_async(pooled_csv_generation,npz_files_name)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
